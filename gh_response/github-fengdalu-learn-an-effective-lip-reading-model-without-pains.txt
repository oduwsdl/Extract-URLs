HTTP/2 200  server: GitHub.com date: Thu, 16 Feb 2023 19:42:33 GMT content-type: application/json; charset=utf-8 content-length: 10612 cache-control: private, max-age=60, s-maxage=60 vary: Accept, Authorization, Cookie, X-GitHub-OTP etag: "d877fc89591a7b530006b05fe34e83e54976e9925f4061a681aa5936a137ffd3" last-modified: Mon, 13 Feb 2023 07:35:19 GMT x-oauth-scopes: admin:enterprise, admin:gpg_key, admin:org, admin:org_hook, admin:public_key, admin:repo_hook, admin:ssh_signing_key, delete:packages, delete_repo, gist, notifications, project, repo, user, workflow, write:discussion, write:packages x-accepted-oauth-scopes: repo x-github-media-type: github.v3; format=json x-github-api-version-selected: 2022-11-28 x-ratelimit-limit: 5000 x-ratelimit-remaining: 3653 x-ratelimit-reset: 1676579728 x-ratelimit-used: 1347 x-ratelimit-resource: core access-control-expose-headers: ETag, Link, Location, Retry-After, X-GitHub-OTP, X-RateLimit-Limit, X-RateLimit-Remaining, X-RateLimit-Used, X-RateLimit-Resource, X-RateLimit-Reset, X-OAuth-Scopes, X-Accepted-OAuth-Scopes, X-Poll-Interval, X-GitHub-Media-Type, X-GitHub-SSO, X-GitHub-Request-Id, Deprecation, Sunset access-control-allow-origin: * strict-transport-security: max-age=31536000; includeSubdomains; preload x-frame-options: deny x-content-type-options: nosniff x-xss-protection: 0 referrer-policy: origin-when-cross-origin, strict-origin-when-cross-origin content-security-policy: default-src 'none' vary: Accept-Encoding, Accept, X-Requested-With x-github-request-id: CAA5:1AF5:37A4699:72221A3:63EE8728  { "id": 313056681, "node_id": "MDEwOlJlcG9zaXRvcnkzMTMwNTY2ODE=", "name": "learn-an-effective-lip-reading-model-without-pains", "full_name": "VIPL-Audio-Visual-Speech-Understanding/learn-an-effective-lip-reading-model-without-pains", "private": false, "owner": { "login": "VIPL-Audio-Visual-Speech-Understanding", "id": 100741894, "node_id": "O_kgDOBgEzBg", "avatar_url": "https://avatars.githubusercontent.com/u/100741894?v=4", "gravatar_id": "", "url": "https://api.github.com/users/VIPL-Audio-Visual-Speech-Understanding", "html_url": "https://github.com/VIPL-Audio-Visual-Speech-Understanding", "followers_url": "https://api.github.com/users/VIPL-Audio-Visual-Speech-Understanding/followers", "following_url": "https://api.github.com/users/VIPL-Audio-Visual-Speech-Understanding/following{/other_user}", "gists_url": "https://api.github.com/users/VIPL-Audio-Visual-Speech-Understanding/gists{/gist_id}", "starred_url": "https://api.github.com/users/VIPL-Audio-Visual-Speech-Understanding/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/VIPL-Audio-Visual-Speech-Understanding/subscriptions", "organizations_url": "https://api.github.com/users/VIPL-Audio-Visual-Speech-Understanding/orgs", "repos_url": "https://api.github.com/users/VIPL-Audio-Visual-Speech-Understanding/repos", "events_url": "https://api.github.com/users/VIPL-Audio-Visual-Speech-Understanding/events{/privacy}", "received_events_url": "https://api.github.com/users/VIPL-Audio-Visual-Speech-Understanding/received_events", "type": "Organization", "site_admin": false }, "html_url": "https://github.com/VIPL-Audio-Visual-Speech-Understanding/learn-an-effective-lip-reading-model-without-pains", "description": "The PyTorch Code and Model In \"Learn an Effective Lip Reading Model without Pains\", (https://arxiv.org/abs/2011.07557), which reaches the state-of-art performance in LRW-1000 dataset.", "fork": false, "url": "https://api.github.com/repos/VIPL-Audio-Visual-Speech-Understanding/learn-an-effective-lip-reading-model-without-pains", "forks_url": "https://api.github.com/repos/VIPL-Audio-Visual-Speech-Understanding/learn-an-effective-lip-reading-model-without-pains/forks", "keys_url": "https://api.github.com/repos/VIPL-Audio-Visual-Speech-Understanding/learn-an-effective-lip-reading-model-without-pains/keys{/key_id}", "collaborators_url": "https://api.github.com/repos/VIPL-Audio-Visual-Speech-Understanding/learn-an-effective-lip-reading-model-without-pains/collaborators{/collaborator}", "teams_url": "https://api.github.com/repos/VIPL-Audio-Visual-Speech-Understanding/learn-an-effective-lip-reading-model-without-pains/teams", "hooks_url": "https://api.github.com/repos/VIPL-Audio-Visual-Speech-Understanding/learn-an-effective-lip-reading-model-without-pains/hooks", "issue_events_url": "https://api.github.com/repos/VIPL-Audio-Visual-Speech-Understanding/learn-an-effective-lip-reading-model-without-pains/issues/events{/number}", "events_url": "https://api.github.com/repos/VIPL-Audio-Visual-Speech-Understanding/learn-an-effective-lip-reading-model-without-pains/events", "assignees_url": "https://api.github.com/repos/VIPL-Audio-Visual-Speech-Understanding/learn-an-effective-lip-reading-model-without-pains/assignees{/user}", "branches_url": "https://api.github.com/repos/VIPL-Audio-Visual-Speech-Understanding/learn-an-effective-lip-reading-model-without-pains/branches{/branch}", "tags_url": "https://api.github.com/repos/VIPL-Audio-Visual-Speech-Understanding/learn-an-effective-lip-reading-model-without-pains/tags", "blobs_url": "https://api.github.com/repos/VIPL-Audio-Visual-Speech-Understanding/learn-an-effective-lip-reading-model-without-pains/git/blobs{/sha}", "git_tags_url": "https://api.github.com/repos/VIPL-Audio-Visual-Speech-Understanding/learn-an-effective-lip-reading-model-without-pains/git/tags{/sha}", "git_refs_url": "https://api.github.com/repos/VIPL-Audio-Visual-Speech-Understanding/learn-an-effective-lip-reading-model-without-pains/git/refs{/sha}", "trees_url": "https://api.github.com/repos/VIPL-Audio-Visual-Speech-Understanding/learn-an-effective-lip-reading-model-without-pains/git/trees{/sha}", "statuses_url": "https://api.github.com/repos/VIPL-Audio-Visual-Speech-Understanding/learn-an-effective-lip-reading-model-without-pains/statuses/{sha}", "languages_url": "https://api.github.com/repos/VIPL-Audio-Visual-Speech-Understanding/learn-an-effective-lip-reading-model-without-pains/languages", "stargazers_url": "https://api.github.com/repos/VIPL-Audio-Visual-Speech-Understanding/learn-an-effective-lip-reading-model-without-pains/stargazers", "contributors_url": "https://api.github.com/repos/VIPL-Audio-Visual-Speech-Understanding/learn-an-effective-lip-reading-model-without-pains/contributors", "subscribers_url": "https://api.github.com/repos/VIPL-Audio-Visual-Speech-Understanding/learn-an-effective-lip-reading-model-without-pains/subscribers", "subscription_url": "https://api.github.com/repos/VIPL-Audio-Visual-Speech-Understanding/learn-an-effective-lip-reading-model-without-pains/subscription", "commits_url": "https://api.github.com/repos/VIPL-Audio-Visual-Speech-Understanding/learn-an-effective-lip-reading-model-without-pains/commits{/sha}", "git_commits_url": "https://api.github.com/repos/VIPL-Audio-Visual-Speech-Understanding/learn-an-effective-lip-reading-model-without-pains/git/commits{/sha}", "comments_url": "https://api.github.com/repos/VIPL-Audio-Visual-Speech-Understanding/learn-an-effective-lip-reading-model-without-pains/comments{/number}", "issue_comment_url": "https://api.github.com/repos/VIPL-Audio-Visual-Speech-Understanding/learn-an-effective-lip-reading-model-without-pains/issues/comments{/number}", "contents_url": "https://api.github.com/repos/VIPL-Audio-Visual-Speech-Understanding/learn-an-effective-lip-reading-model-without-pains/contents/{+path}", "compare_url": "https://api.github.com/repos/VIPL-Audio-Visual-Speech-Understanding/learn-an-effective-lip-reading-model-without-pains/compare/{base}...{head}", "merges_url": "https://api.github.com/repos/VIPL-Audio-Visual-Speech-Understanding/learn-an-effective-lip-reading-model-without-pains/merges", "archive_url": "https://api.github.com/repos/VIPL-Audio-Visual-Speech-Understanding/learn-an-effective-lip-reading-model-without-pains/{archive_format}{/ref}", "downloads_url": "https://api.github.com/repos/VIPL-Audio-Visual-Speech-Understanding/learn-an-effective-lip-reading-model-without-pains/downloads", "issues_url": "https://api.github.com/repos/VIPL-Audio-Visual-Speech-Understanding/learn-an-effective-lip-reading-model-without-pains/issues{/number}", "pulls_url": "https://api.github.com/repos/VIPL-Audio-Visual-Speech-Understanding/learn-an-effective-lip-reading-model-without-pains/pulls{/number}", "milestones_url": "https://api.github.com/repos/VIPL-Audio-Visual-Speech-Understanding/learn-an-effective-lip-reading-model-without-pains/milestones{/number}", "notifications_url": "https://api.github.com/repos/VIPL-Audio-Visual-Speech-Understanding/learn-an-effective-lip-reading-model-without-pains/notifications{?since,all,participating}", "labels_url": "https://api.github.com/repos/VIPL-Audio-Visual-Speech-Understanding/learn-an-effective-lip-reading-model-without-pains/labels{/name}", "releases_url": "https://api.github.com/repos/VIPL-Audio-Visual-Speech-Understanding/learn-an-effective-lip-reading-model-without-pains/releases{/id}", "deployments_url": "https://api.github.com/repos/VIPL-Audio-Visual-Speech-Understanding/learn-an-effective-lip-reading-model-without-pains/deployments", "created_at": "2020-11-15T15:05:17Z", "updated_at": "2023-02-13T07:35:19Z", "pushed_at": "2022-09-21T06:36:14Z", "git_url": "git://github.com/VIPL-Audio-Visual-Speech-Understanding/learn-an-effective-lip-reading-model-without-pains.git", "ssh_url": "git@github.com:VIPL-Audio-Visual-Speech-Understanding/learn-an-effective-lip-reading-model-without-pains.git", "clone_url": "https://github.com/VIPL-Audio-Visual-Speech-Understanding/learn-an-effective-lip-reading-model-without-pains.git", "svn_url": "https://github.com/VIPL-Audio-Visual-Speech-Understanding/learn-an-effective-lip-reading-model-without-pains", "homepage": "", "size": 48, "stargazers_count": 121, "watchers_count": 121, "language": "Python", "has_issues": true, "has_projects": true, "has_downloads": true, "has_wiki": true, "has_pages": false, "has_discussions": false, "forks_count": 28, "mirror_url": null, "archived": false, "disabled": false, "open_issues_count": 5, "license": null, "allow_forking": true, "is_template": false, "web_commit_signoff_required": false, "topics": [ "deep-learning", "lipreading", "pytorch" ], "visibility": "public", "forks": 28, "open_issues": 5, "watchers": 121, "default_branch": "master", "permissions": { "admin": false, "maintain": false, "push": false, "triage": false, "pull": true }, "temp_clone_token": "", "organization": { "login": "VIPL-Audio-Visual-Speech-Understanding", "id": 100741894, "node_id": "O_kgDOBgEzBg", "avatar_url": "https://avatars.githubusercontent.com/u/100741894?v=4", "gravatar_id": "", "url": "https://api.github.com/users/VIPL-Audio-Visual-Speech-Understanding", "html_url": "https://github.com/VIPL-Audio-Visual-Speech-Understanding", "followers_url": "https://api.github.com/users/VIPL-Audio-Visual-Speech-Understanding/followers", "following_url": "https://api.github.com/users/VIPL-Audio-Visual-Speech-Understanding/following{/other_user}", "gists_url": "https://api.github.com/users/VIPL-Audio-Visual-Speech-Understanding/gists{/gist_id}", "starred_url": "https://api.github.com/users/VIPL-Audio-Visual-Speech-Understanding/starred{/owner}{/repo}", "subscriptions_url": "https://api.github.com/users/VIPL-Audio-Visual-Speech-Understanding/subscriptions", "organizations_url": "https://api.github.com/users/VIPL-Audio-Visual-Speech-Understanding/orgs", "repos_url": "https://api.github.com/users/VIPL-Audio-Visual-Speech-Understanding/repos", "events_url": "https://api.github.com/users/VIPL-Audio-Visual-Speech-Understanding/events{/privacy}", "received_events_url": "https://api.github.com/users/VIPL-Audio-Visual-Speech-Understanding/received_events", "type": "Organization", "site_admin": false }, "network_count": 28, "subscribers_count": 1 }
